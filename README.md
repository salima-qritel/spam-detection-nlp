# Spam Detection NLP

![Python](https://img.shields.io/badge/python-3.10-blue)
![TensorFlow](https://img.shields.io/badge/tensorflow-2.x-orange)
![Transformers](https://img.shields.io/badge/transformers-BERT-lightgrey)


## Description

Ce projet impl√©mente un syst√®me de d√©tection de spam pour emails utilisant **NLP (Natural Language Processing)**.  
Il compare plusieurs approches de mod√©lisation :  

1. **RNN (Recurrent Neural Network)**
2. **LSTM avec m√©canisme d‚Äôattention**
3. **Transformers (BERT)**

Le pipeline complet comprend :

- Chargement et inspection des donn√©es
- Pr√©traitement et nettoyage des messages
- Tokenization et encodage
- Mod√©lisation avec diff√©rentes architectures
- √âvaluation et comparaison des mod√®les

---

## Dataset

Le dataset utilis√© est un CSV d‚Äôemails contenant :

- `label` : `ham` ou `spam`  
- `message` : contenu du message  

Apr√®s nettoyage, seules les colonnes `clean_text` et `label` sont conserv√©es.

**Shape initiale :** `(5572, 2)`  
**Shape apr√®s suppression des doublons :** `(5172, 2)`

---

## Pr√©traitement

- Suppression des doublons
- Nettoyage du texte (minuscules, suppression des caract√®res sp√©ciaux, tokenization, lemmatisation)
- Suppression des stopwords
- Encodage des labels (`ham` ‚Üí 0, `spam` ‚Üí 1)
- Transformation en s√©quences pour RNN/LSTM avec padding pour uniformiser les longueurs

---

## Mod√©lisation

### 1. RNN
- **Architecture :**
  - Embedding Layer
  - SimpleRNN (64 unit√©s)
  - Dropout (0.5)
  - Dense (sigmoid)
- **R√©sultats :**
  - Accuracy : 96 %
  - Pr√©cision Ham : 0.98
  - Rappel Ham : 0.97
  - Pr√©cision Spam : 0.84
  - Rappel Spam : 0.88

### 2. LSTM + Attention
- **Architecture :**
  - Embedding Layer
  - LSTM (64 unit√©s, return_sequences=True)
  - Attention
  - Flatten ‚Üí Dropout (0.5)
  - Dense (sigmoid)
- **R√©sultats :**
  - Accuracy : 98 %
  - Pr√©cision Ham : 0.99
  - Rappel Ham : 0.99
  - Pr√©cision Spam : 0.94
  - Rappel Spam : 0.92

### 3. Transformers (BERT)
- **Architecture :**
  - `bert-base-uncased` pour la classification
  - Tokenizer BERT
  - Fine-tuning sur le dataset
- **R√©sultats :**
  - Accuracy : 99 %
  - Pr√©cision Ham : 0.99
  - Rappel Ham : 1.00
  - Pr√©cision Spam : 0.98
  - Rappel Spam : 0.93

**Conclusion :** BERT offre la meilleure performance globale et une excellente d√©tection des spams tout en conservant une haute pr√©cision pour les emails l√©gitimes.

---

## Installation

```bash
# Cloner le d√©p√¥t
git clone https://github.com/votre-utilisateur/spam-detection-nlp.git
cd spam-detection-nlp

# Cr√©er un environnement
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```
## Usage

**1.** Placer le fichier spam.csv dans le dossier du projet

**2.** Lancer le notebook ou script Python

**3.** Le pipeline effectuera :

    - Pr√©traitement

    - Entra√Ænement du mod√®le (RNN, LSTM ou BERT)

    - √âvaluation et visualisation des r√©sultats

## Visualisations

 - Matrice de confusion annot√©e pour chaque mod√®le

 - Scores d‚Äôattention pour LSTM + Attention

 - Comparaison des m√©triques RNN vs LSTM vs BERT
## üßë‚Äçüíª Author

**Salima Qritel**

* GitHub: [@salima-qritel](https://github.com/salima-qritel)
